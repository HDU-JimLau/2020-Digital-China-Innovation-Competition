{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:18:02.731931Z",
     "start_time": "2020-02-21T09:18:01.946323Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', 160)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', 60)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:18:53.641748Z",
     "start_time": "2020-02-21T09:18:53.637729Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax of vector x.\"\"\"\n",
    "    exps = np.exp(x)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:20:36.505396Z",
     "start_time": "2020-02-21T09:20:36.498220Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:22:44.943452Z",
     "start_time": "2020-02-21T09:22:44.131957Z"
    }
   },
   "outputs": [],
   "source": [
    "data1.apply(lambda x:softmax(x),axis=1).to_csv(\"./submit/PROB_softmax_result_0.92512_2020-02-21-16-48-55.csv\",header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T10:07:44.920351Z",
     "start_time": "2020-02-21T10:07:44.125562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.069292</td>\n",
       "      <td>0.557548</td>\n",
       "      <td>0.373160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843214</td>\n",
       "      <td>0.110366</td>\n",
       "      <td>0.046420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.942660</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.025943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.993439</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.005230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>0.993835</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.002719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.926530</td>\n",
       "      <td>0.035249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>0.183257</td>\n",
       "      <td>0.645602</td>\n",
       "      <td>0.171140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>0.926162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.990131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.069292  0.557548  0.373160\n",
       "1     0.843214  0.110366  0.046420\n",
       "2     0.942660  0.031397  0.025943\n",
       "3     0.993439  0.003632  0.002929\n",
       "4     0.986441  0.008329  0.005230\n",
       "...        ...       ...       ...\n",
       "1995  0.993835  0.003447  0.002719\n",
       "1996  0.038221  0.926530  0.035249\n",
       "1997  0.183257  0.645602  0.171140\n",
       "1998  0.049559  0.024279  0.926162\n",
       "1999  0.006296  0.003574  0.990131\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.apply(lambda x:softmax(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T10:08:11.898996Z",
     "start_time": "2020-02-21T10:08:11.862111Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "type_map_rev = {0: '拖网', 1: '围网', 2: '刺网'}\n",
    "\n",
    "data1 = pd.read_csv(\"./submit/PROB_softmax_result_0.92512_2020-02-21-16-48-55.csv\",header=None).values\n",
    "data2 = pd.read_csv(\"./submit/result_93232B_1405_Pro.csv\").values[:,2:]\n",
    "\n",
    "sub2 = pd.read_csv(\"./submit/result_93232B_1405(1).csv\",header=None)\n",
    "sub2[1] = np.argmax(data1*0.7+data2*0.3,axis=1)\n",
    "sub2[1] = sub2[1].map(type_map_rev)\n",
    "sub2.to_csv('submit/stack_B.csv', index=None, header=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:53:55.173912Z",
     "start_time": "2020-02-21T11:53:55.170236Z"
    }
   },
   "outputs": [],
   "source": [
    "m = np.argmax(data1,axis=1)!=np.argmax(data2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:54:19.366425Z",
     "start_time": "2020-02-21T11:54:19.341944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.458093</td>\n",
       "      <td>0.458538</td>\n",
       "      <td>0.083369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.552285</td>\n",
       "      <td>0.394060</td>\n",
       "      <td>0.053655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.510484</td>\n",
       "      <td>0.468393</td>\n",
       "      <td>0.021123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.031289</td>\n",
       "      <td>0.588076</td>\n",
       "      <td>0.380636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.534303</td>\n",
       "      <td>0.029628</td>\n",
       "      <td>0.436069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1934</td>\n",
       "      <td>0.278148</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.696247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.883441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>0.258017</td>\n",
       "      <td>0.702717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.391315</td>\n",
       "      <td>0.036840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992</td>\n",
       "      <td>0.308807</td>\n",
       "      <td>0.429304</td>\n",
       "      <td>0.261889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "51    0.458093  0.458538  0.083369\n",
       "71    0.552285  0.394060  0.053655\n",
       "86    0.510484  0.468393  0.021123\n",
       "99    0.031289  0.588076  0.380636\n",
       "105   0.534303  0.029628  0.436069\n",
       "...        ...       ...       ...\n",
       "1934  0.278148  0.025605  0.696247\n",
       "1935  0.071397  0.045161  0.883441\n",
       "1990  0.039266  0.258017  0.702717\n",
       "1991  0.571845  0.391315  0.036840\n",
       "1992  0.308807  0.429304  0.261889\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data1)[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:05:24.425234Z",
     "start_time": "2020-02-21T12:05:24.410246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.000532241</td>\n",
       "      <td>0.586079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.469014</td>\n",
       "      <td>0.510391</td>\n",
       "      <td>0.0205947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.486452</td>\n",
       "      <td>0.513195</td>\n",
       "      <td>0.000352837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.00321653</td>\n",
       "      <td>0.563162</td>\n",
       "      <td>0.433622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.40339</td>\n",
       "      <td>0.596171</td>\n",
       "      <td>0.000439396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.354622</td>\n",
       "      <td>0.51726</td>\n",
       "      <td>0.128118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.472403</td>\n",
       "      <td>0.470064</td>\n",
       "      <td>0.0575331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.528046</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.307892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.45914</td>\n",
       "      <td>0.540576</td>\n",
       "      <td>0.000284494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>0.0485734</td>\n",
       "      <td>0.402408</td>\n",
       "      <td>0.549019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>0.507835</td>\n",
       "      <td>0.476334</td>\n",
       "      <td>0.0158306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>0.473217</td>\n",
       "      <td>0.26179</td>\n",
       "      <td>0.264992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>746</td>\n",
       "      <td>0.000618849</td>\n",
       "      <td>0.488859</td>\n",
       "      <td>0.510522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>809</td>\n",
       "      <td>0.502405</td>\n",
       "      <td>0.497324</td>\n",
       "      <td>0.000271314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>0.585029</td>\n",
       "      <td>0.352874</td>\n",
       "      <td>0.0620967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>0.083174</td>\n",
       "      <td>0.501157</td>\n",
       "      <td>0.415669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>969</td>\n",
       "      <td>0.00110472</td>\n",
       "      <td>0.486503</td>\n",
       "      <td>0.512392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.551191</td>\n",
       "      <td>0.423055</td>\n",
       "      <td>0.0257547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.000178238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1073</td>\n",
       "      <td>0.374725</td>\n",
       "      <td>0.0851488</td>\n",
       "      <td>0.540126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1074</td>\n",
       "      <td>0.489786</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.00454865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.506277</td>\n",
       "      <td>0.482912</td>\n",
       "      <td>0.0108111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1151</td>\n",
       "      <td>0.215895</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>0.455603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1177</td>\n",
       "      <td>0.444437</td>\n",
       "      <td>0.245853</td>\n",
       "      <td>0.309711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1178</td>\n",
       "      <td>0.57257</td>\n",
       "      <td>0.42632</td>\n",
       "      <td>0.00110955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1207</td>\n",
       "      <td>0.000592045</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.572608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.538941</td>\n",
       "      <td>0.460847</td>\n",
       "      <td>0.000212536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>0.512469</td>\n",
       "      <td>0.486281</td>\n",
       "      <td>0.00125086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1354</td>\n",
       "      <td>0.00604017</td>\n",
       "      <td>0.41391</td>\n",
       "      <td>0.58005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>0.269666</td>\n",
       "      <td>0.328905</td>\n",
       "      <td>0.401429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1635</td>\n",
       "      <td>0.251003</td>\n",
       "      <td>0.327203</td>\n",
       "      <td>0.421795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1636</td>\n",
       "      <td>0.47408</td>\n",
       "      <td>0.524894</td>\n",
       "      <td>0.00102525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1681</td>\n",
       "      <td>0.546495</td>\n",
       "      <td>0.278735</td>\n",
       "      <td>0.17477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1748</td>\n",
       "      <td>0.590422</td>\n",
       "      <td>0.394764</td>\n",
       "      <td>0.0148137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1796</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.161095</td>\n",
       "      <td>0.402305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1812</td>\n",
       "      <td>0.405534</td>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.425445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1845</td>\n",
       "      <td>0.000778615</td>\n",
       "      <td>0.509761</td>\n",
       "      <td>0.48946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.00137273</td>\n",
       "      <td>0.502692</td>\n",
       "      <td>0.495935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>0.488096</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.315867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1921</td>\n",
       "      <td>0.521074</td>\n",
       "      <td>0.453655</td>\n",
       "      <td>0.0252715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>0.505871</td>\n",
       "      <td>0.0107364</td>\n",
       "      <td>0.483393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1934</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.0098615</td>\n",
       "      <td>0.478305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2\n",
       "105      0.413389  0.000532241     0.586079\n",
       "119      0.469014     0.510391    0.0205947\n",
       "300      0.486452     0.513195  0.000352837\n",
       "303    0.00321653     0.563162     0.433622\n",
       "374       0.40339     0.596171  0.000439396\n",
       "381      0.354622      0.51726     0.128118\n",
       "442      0.472403     0.470064    0.0575331\n",
       "485      0.528046     0.164062     0.307892\n",
       "496       0.45914     0.540576  0.000284494\n",
       "698     0.0485734     0.402408     0.549019\n",
       "702      0.507835     0.476334    0.0158306\n",
       "736      0.473217      0.26179     0.264992\n",
       "746   0.000618849     0.488859     0.510522\n",
       "809      0.502405     0.497324  0.000271314\n",
       "956      0.585029     0.352874    0.0620967\n",
       "963      0.083174     0.501157     0.415669\n",
       "969    0.00110472     0.486503     0.512392\n",
       "980      0.551191     0.423055    0.0257547\n",
       "996      0.496088     0.503734  0.000178238\n",
       "1073     0.374725    0.0851488     0.540126\n",
       "1074     0.489786     0.505665   0.00454865\n",
       "1100     0.506277     0.482912    0.0108111\n",
       "1151     0.215895     0.328502     0.455603\n",
       "1177     0.444437     0.245853     0.309711\n",
       "1178      0.57257      0.42632   0.00110955\n",
       "1207  0.000592045       0.4268     0.572608\n",
       "1225     0.538941     0.460847  0.000212536\n",
       "1265     0.512469     0.486281   0.00125086\n",
       "1354   0.00604017      0.41391      0.58005\n",
       "1456     0.269666     0.328905     0.401429\n",
       "1635     0.251003     0.327203     0.421795\n",
       "1636      0.47408     0.524894   0.00102525\n",
       "1681     0.546495     0.278735      0.17477\n",
       "1748     0.590422     0.394764    0.0148137\n",
       "1796       0.4366     0.161095     0.402305\n",
       "1812     0.405534     0.169021     0.425445\n",
       "1845  0.000778615     0.509761      0.48946\n",
       "1850   0.00137273     0.502692     0.495935\n",
       "1919     0.488096     0.196038     0.315867\n",
       "1921     0.521074     0.453655    0.0252715\n",
       "1925     0.505871    0.0107364     0.483393\n",
       "1934     0.511834    0.0098615     0.478305"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data2)[m][np.max(pd.DataFrame(data2)[m],axis=1)<0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:54:28.779427Z",
     "start_time": "2020-02-21T11:54:28.758185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.923483</td>\n",
       "      <td>0.0542877</td>\n",
       "      <td>0.0222294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.111413</td>\n",
       "      <td>0.882244</td>\n",
       "      <td>0.00634253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.264927</td>\n",
       "      <td>0.728241</td>\n",
       "      <td>0.00683158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.000309593</td>\n",
       "      <td>0.0936732</td>\n",
       "      <td>0.906017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>0.000532241</td>\n",
       "      <td>0.586079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1934</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.0098615</td>\n",
       "      <td>0.478305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935</td>\n",
       "      <td>0.767112</td>\n",
       "      <td>0.0212245</td>\n",
       "      <td>0.211664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>0.00235412</td>\n",
       "      <td>0.674429</td>\n",
       "      <td>0.323217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991</td>\n",
       "      <td>0.355762</td>\n",
       "      <td>0.642172</td>\n",
       "      <td>0.00206633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992</td>\n",
       "      <td>0.113457</td>\n",
       "      <td>0.0757044</td>\n",
       "      <td>0.810839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1           2\n",
       "51       0.923483    0.0542877   0.0222294\n",
       "71       0.111413     0.882244  0.00634253\n",
       "86       0.264927     0.728241  0.00683158\n",
       "99    0.000309593    0.0936732    0.906017\n",
       "105      0.413389  0.000532241    0.586079\n",
       "...           ...          ...         ...\n",
       "1934     0.511834    0.0098615    0.478305\n",
       "1935     0.767112    0.0212245    0.211664\n",
       "1990   0.00235412     0.674429    0.323217\n",
       "1991     0.355762     0.642172  0.00206633\n",
       "1992     0.113457    0.0757044    0.810839\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T09:21:28.413353Z",
     "start_time": "2020-02-21T09:21:28.409502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06929238, 0.55754766, 0.37315996])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(data1.values[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:47:13.426725Z",
     "start_time": "2020-02-09T05:47:13.336960Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\jupyter\\智慧海洋\\tianchi_ship_2019-master\\working\\正式版\\复现特征/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:47:13.593297Z",
     "start_time": "2020-02-09T05:47:13.587295Z"
    }
   },
   "outputs": [],
   "source": [
    "base_fea = ['ship', 'x', 'y', 'v', 'd', 'time', 'type', 'date', 'hour', 'weekday',\n",
    "       'x_max', 'x_min', 'x_mean', 'x_std', 'x_skew', 'x_sum', 'x_count',\n",
    "       'y_max', 'y_min', 'y_mean', 'y_std', 'y_skew', 'y_sum', 'v_max',\n",
    "       'v_min', 'v_mean', 'v_std', 'v_skew', 'v_sum', 'd_max', 'd_min',\n",
    "       'd_mean', 'd_std', 'd_skew', 'd_sum', 'x_max_x_min', 'y_max_y_min',\n",
    "       'y_max_x_min', 'x_max_y_min', 'slope', 'area', 'mode_hour', 'hour_max',\n",
    "       'hour_min', 'hour_nunique', 'date_nunique', 'diff_time', 'diff_day',\n",
    "       'diff_second']\n",
    "# base_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:48:57.597560Z",
     "start_time": "2020-02-09T05:48:57.592574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['w2c_date-v_93', 'w2c_date-v_94', 'w2c_date-v_95', 'w2c_date-v_96',\n",
       "       'w2c_date-v_97', 'w2c_date-v_98', 'w2c_date-v_99', 'cut_0', 'cut_1',\n",
       "       'cut_2', 'cut_3', 'cut_4', 'cut_5', 'cut_6', 'cut_7', 'cut_8', 'cut_9',\n",
       "       'cut_10', 'cut_11', 'cut_12', 'cut_13', 'cut_14', 'cut_v_0', 'cut_v_1',\n",
       "       'cut_v_2', 'cut_v_3', 'cut_v_4', 'cut_v_5', 'cut_v_6', 'cut_v_7',\n",
       "       'cut_v_8', 'cut_v_9', 'cut_v_10', 'cut_v_11', 'cut_v_12', 'cut_v_13',\n",
       "       'cut_v_14', 'cut_d_0', 'cut_d_1', 'cut_d_2', 'cut_d_3', 'cut_d_4',\n",
       "       'cut_d_5', 'cut_d_6', 'cut_d_7', 'cut_d_8', 'cut_d_9', 'cut_d_10',\n",
       "       'cut_d_11', 'w2c_x-y-v-1000_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[-250:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:47:14.008820Z",
     "start_time": "2020-02-09T05:47:13.970921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v</th>\n",
       "      <th>d</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>x_max</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_skew</th>\n",
       "      <th>x_sum</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_max</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_skew</th>\n",
       "      <th>y_sum</th>\n",
       "      <th>v_max</th>\n",
       "      <th>v_min</th>\n",
       "      <th>v_mean</th>\n",
       "      <th>v_std</th>\n",
       "      <th>v_skew</th>\n",
       "      <th>v_sum</th>\n",
       "      <th>d_max</th>\n",
       "      <th>d_min</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_std</th>\n",
       "      <th>d_skew</th>\n",
       "      <th>d_sum</th>\n",
       "      <th>x_max_x_min</th>\n",
       "      <th>y_max_y_min</th>\n",
       "      <th>y_max_x_min</th>\n",
       "      <th>x_max_y_min</th>\n",
       "      <th>slope</th>\n",
       "      <th>area</th>\n",
       "      <th>mode_hour</th>\n",
       "      <th>hour_max</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>hour_nunique</th>\n",
       "      <th>date_nunique</th>\n",
       "      <th>diff_time</th>\n",
       "      <th>diff_day</th>\n",
       "      <th>diff_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>2.59</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>1900-11-10 11:58:19</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>6.119351e+06</td>\n",
       "      <td>5037.320747</td>\n",
       "      <td>5.255558</td>\n",
       "      <td>2.533411e+09</td>\n",
       "      <td>414</td>\n",
       "      <td>5.130781e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>5.130494e+06</td>\n",
       "      <td>850.264541</td>\n",
       "      <td>-4.762308</td>\n",
       "      <td>2.124025e+09</td>\n",
       "      <td>9.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265966</td>\n",
       "      <td>1.321248</td>\n",
       "      <td>5.520205</td>\n",
       "      <td>110.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.629320</td>\n",
       "      <td>0.945962</td>\n",
       "      <td>0.251140</td>\n",
       "      <td>-4.607238</td>\n",
       "      <td>391.628240</td>\n",
       "      <td>33686.667453</td>\n",
       "      <td>5907.975523</td>\n",
       "      <td>-9.875704e+05</td>\n",
       "      <td>1.027165e+06</td>\n",
       "      <td>0.175380</td>\n",
       "      <td>1.990200e+08</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:48:51.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.076254e+06</td>\n",
       "      <td>5.061743e+06</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.139173</td>\n",
       "      <td>1900-11-10 11:40:21</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.102450e+06</td>\n",
       "      <td>6.049472e+06</td>\n",
       "      <td>6.091460e+06</td>\n",
       "      <td>16543.394419</td>\n",
       "      <td>-1.058454</td>\n",
       "      <td>2.345212e+09</td>\n",
       "      <td>385</td>\n",
       "      <td>5.112874e+06</td>\n",
       "      <td>5.042857e+06</td>\n",
       "      <td>5.094050e+06</td>\n",
       "      <td>26764.042729</td>\n",
       "      <td>-0.802446</td>\n",
       "      <td>1.961209e+09</td>\n",
       "      <td>10.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.607922</td>\n",
       "      <td>2.412688</td>\n",
       "      <td>1.590284</td>\n",
       "      <td>619.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>0.637959</td>\n",
       "      <td>-1.303134</td>\n",
       "      <td>231.330402</td>\n",
       "      <td>52978.013345</td>\n",
       "      <td>70016.655842</td>\n",
       "      <td>-9.365979e+05</td>\n",
       "      <td>1.059593e+06</td>\n",
       "      <td>1.321617</td>\n",
       "      <td>3.709343e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:39:47.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.321032e+06</td>\n",
       "      <td>5.242805e+06</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-0.838671</td>\n",
       "      <td>1900-11-10 11:49:36</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.346913e+06</td>\n",
       "      <td>6.246119e+06</td>\n",
       "      <td>6.262484e+06</td>\n",
       "      <td>32280.567149</td>\n",
       "      <td>1.623040</td>\n",
       "      <td>2.486206e+09</td>\n",
       "      <td>397</td>\n",
       "      <td>5.265810e+06</td>\n",
       "      <td>5.229867e+06</td>\n",
       "      <td>5.242458e+06</td>\n",
       "      <td>5975.460236</td>\n",
       "      <td>2.198003</td>\n",
       "      <td>2.081256e+09</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.313854</td>\n",
       "      <td>2.442825</td>\n",
       "      <td>2.145410</td>\n",
       "      <td>521.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999391</td>\n",
       "      <td>0.350460</td>\n",
       "      <td>0.705955</td>\n",
       "      <td>-0.633320</td>\n",
       "      <td>139.132494</td>\n",
       "      <td>100794.674835</td>\n",
       "      <td>35942.703641</td>\n",
       "      <td>-9.803087e+05</td>\n",
       "      <td>1.117046e+06</td>\n",
       "      <td>0.356593</td>\n",
       "      <td>3.622833e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:33:53.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>6.102751e+06</td>\n",
       "      <td>5.112534e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900-10-30 23:50:05</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-10-30</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.151439e+06</td>\n",
       "      <td>6.102326e+06</td>\n",
       "      <td>6.123711e+06</td>\n",
       "      <td>14451.941954</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>2.516845e+09</td>\n",
       "      <td>411</td>\n",
       "      <td>5.112752e+06</td>\n",
       "      <td>5.069616e+06</td>\n",
       "      <td>5.085480e+06</td>\n",
       "      <td>14020.260117</td>\n",
       "      <td>1.055676</td>\n",
       "      <td>2.090132e+09</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.965864</td>\n",
       "      <td>1.647069</td>\n",
       "      <td>-0.215287</td>\n",
       "      <td>1218.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.981627</td>\n",
       "      <td>0.224864</td>\n",
       "      <td>0.518319</td>\n",
       "      <td>0.053032</td>\n",
       "      <td>92.419078</td>\n",
       "      <td>49113.022232</td>\n",
       "      <td>43135.705758</td>\n",
       "      <td>-9.895740e+05</td>\n",
       "      <td>1.081823e+06</td>\n",
       "      <td>0.878295</td>\n",
       "      <td>2.118525e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:48:47.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>6.843713e+06</td>\n",
       "      <td>5.480538e+06</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>1900-11-06 23:42:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-11-06</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.844414e+06</td>\n",
       "      <td>6.748890e+06</td>\n",
       "      <td>6.807536e+06</td>\n",
       "      <td>26263.537565</td>\n",
       "      <td>-0.770190</td>\n",
       "      <td>2.566441e+09</td>\n",
       "      <td>377</td>\n",
       "      <td>5.540087e+06</td>\n",
       "      <td>5.440815e+06</td>\n",
       "      <td>5.464764e+06</td>\n",
       "      <td>30135.645906</td>\n",
       "      <td>1.412544</td>\n",
       "      <td>2.060216e+09</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.085570</td>\n",
       "      <td>2.649306</td>\n",
       "      <td>1.110173</td>\n",
       "      <td>786.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>0.711243</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>-5.284929</td>\n",
       "      <td>95524.035775</td>\n",
       "      <td>99271.486171</td>\n",
       "      <td>-1.208803e+06</td>\n",
       "      <td>1.403598e+06</td>\n",
       "      <td>1.039230</td>\n",
       "      <td>9.482813e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:37:11.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ship             x             y     v         d                 time  \\\n",
       "0     0  6.152038e+06  5.124873e+06  2.59 -0.207912  1900-11-10 11:58:19   \n",
       "1     1  6.076254e+06  5.061743e+06  3.99  0.139173  1900-11-10 11:40:21   \n",
       "2    10  6.321032e+06  5.242805e+06  4.48 -0.838671  1900-11-10 11:49:36   \n",
       "3   100  6.102751e+06  5.112534e+06  0.00  1.000000  1900-10-30 23:50:05   \n",
       "4  1000  6.843713e+06  5.480538e+06  2.00 -0.809017  1900-11-06 23:42:30   \n",
       "\n",
       "   type        date  hour  weekday         x_max         x_min        x_mean  \\\n",
       "0     0  1900-11-10    11        5  6.152038e+06  6.118352e+06  6.119351e+06   \n",
       "1     0  1900-11-10    11        5  6.102450e+06  6.049472e+06  6.091460e+06   \n",
       "2     0  1900-11-10    11        5  6.346913e+06  6.246119e+06  6.262484e+06   \n",
       "3     0  1900-10-30    23        1  6.151439e+06  6.102326e+06  6.123711e+06   \n",
       "4     1  1900-11-06    23        1  6.844414e+06  6.748890e+06  6.807536e+06   \n",
       "\n",
       "          x_std    x_skew         x_sum  x_count         y_max         y_min  \\\n",
       "0   5037.320747  5.255558  2.533411e+09      414  5.130781e+06  5.124873e+06   \n",
       "1  16543.394419 -1.058454  2.345212e+09      385  5.112874e+06  5.042857e+06   \n",
       "2  32280.567149  1.623040  2.486206e+09      397  5.265810e+06  5.229867e+06   \n",
       "3  14451.941954  0.021860  2.516845e+09      411  5.112752e+06  5.069616e+06   \n",
       "4  26263.537565 -0.770190  2.566441e+09      377  5.540087e+06  5.440815e+06   \n",
       "\n",
       "         y_mean         y_std    y_skew         y_sum  v_max  v_min    v_mean  \\\n",
       "0  5.130494e+06    850.264541 -4.762308  2.124025e+09   9.39    0.0  0.265966   \n",
       "1  5.094050e+06  26764.042729 -0.802446  1.961209e+09  10.47    0.0  1.607922   \n",
       "2  5.242458e+06   5975.460236  2.198003  2.081256e+09  10.09    0.0  1.313854   \n",
       "3  5.085480e+06  14020.260117  1.055676  2.090132e+09   8.69    0.0  2.965864   \n",
       "4  5.464764e+06  30135.645906  1.412544  2.060216e+09   8.90    0.0  2.085570   \n",
       "\n",
       "      v_std    v_skew    v_sum  d_max     d_min    d_mean     d_std    d_skew  \\\n",
       "0  1.321248  5.520205   110.11    1.0 -0.629320  0.945962  0.251140 -4.607238   \n",
       "1  2.412688  1.590284   619.05    1.0 -0.999848  0.600858  0.637959 -1.303134   \n",
       "2  2.442825  2.145410   521.60    1.0 -0.999391  0.350460  0.705955 -0.633320   \n",
       "3  1.647069 -0.215287  1218.97    1.0 -0.981627  0.224864  0.518319  0.053032   \n",
       "4  2.649306  1.110173   786.26    1.0 -0.999848 -0.014018  0.711243  0.056856   \n",
       "\n",
       "        d_sum    x_max_x_min   y_max_y_min   y_max_x_min   x_max_y_min  \\\n",
       "0  391.628240   33686.667453   5907.975523 -9.875704e+05  1.027165e+06   \n",
       "1  231.330402   52978.013345  70016.655842 -9.365979e+05  1.059593e+06   \n",
       "2  139.132494  100794.674835  35942.703641 -9.803087e+05  1.117046e+06   \n",
       "3   92.419078   49113.022232  43135.705758 -9.895740e+05  1.081823e+06   \n",
       "4   -5.284929   95524.035775  99271.486171 -1.208803e+06  1.403598e+06   \n",
       "\n",
       "      slope          area  mode_hour  hour_max  hour_min  hour_nunique  \\\n",
       "0  0.175380  1.990200e+08         15        23         0            24   \n",
       "1  1.321617  3.709343e+09         19        23         0            24   \n",
       "2  0.356593  3.622833e+09         23        23         0            24   \n",
       "3  0.878295  2.118525e+09         11        23         0            24   \n",
       "4  1.039230  9.482813e+09          0        23         0            24   \n",
       "\n",
       "   date_nunique                  diff_time  diff_day  diff_second  \n",
       "0             4  2 days 23:48:51.000000000         2        85731  \n",
       "1             4  2 days 23:39:47.000000000         2        85187  \n",
       "2             4  2 days 23:33:53.000000000         2        84833  \n",
       "3             3  2 days 23:48:47.000000000         2        85727  \n",
       "4             3  2 days 23:37:11.000000000         2        85031  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[base_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T06:03:09.055188Z",
     "start_time": "2020-02-09T06:03:08.971416Z"
    }
   },
   "outputs": [],
   "source": [
    "data_my = pd.read_csv(r\"E:\\jupyter\\智慧海洋\\tianchi_ship_2019-master\\working\\复现代码\\temp\\basefea/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T06:03:09.465597Z",
     "start_time": "2020-02-09T06:03:09.410772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v</th>\n",
       "      <th>d</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>x_max</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_skew</th>\n",
       "      <th>x_sum</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_max</th>\n",
       "      <th>y_min</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>y_skew</th>\n",
       "      <th>y_sum</th>\n",
       "      <th>v_max</th>\n",
       "      <th>v_min</th>\n",
       "      <th>v_mean</th>\n",
       "      <th>v_std</th>\n",
       "      <th>v_skew</th>\n",
       "      <th>v_sum</th>\n",
       "      <th>d_max</th>\n",
       "      <th>d_min</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_std</th>\n",
       "      <th>d_skew</th>\n",
       "      <th>d_sum</th>\n",
       "      <th>x_max_x_min</th>\n",
       "      <th>y_max_y_min</th>\n",
       "      <th>y_max_x_min</th>\n",
       "      <th>x_max_y_min</th>\n",
       "      <th>slope</th>\n",
       "      <th>area</th>\n",
       "      <th>mode_hour</th>\n",
       "      <th>hour_max</th>\n",
       "      <th>hour_min</th>\n",
       "      <th>hour_nunique</th>\n",
       "      <th>date_nunique</th>\n",
       "      <th>diff_time</th>\n",
       "      <th>diff_day</th>\n",
       "      <th>diff_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>2.59</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>1900-11-10 11:58:19</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.152038e+06</td>\n",
       "      <td>6.118352e+06</td>\n",
       "      <td>6.119351e+06</td>\n",
       "      <td>5037.320747</td>\n",
       "      <td>5.255558</td>\n",
       "      <td>2.533411e+09</td>\n",
       "      <td>414</td>\n",
       "      <td>5.130781e+06</td>\n",
       "      <td>5.124873e+06</td>\n",
       "      <td>5.130494e+06</td>\n",
       "      <td>850.264541</td>\n",
       "      <td>-4.762308</td>\n",
       "      <td>2.124025e+09</td>\n",
       "      <td>9.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.265966</td>\n",
       "      <td>1.321248</td>\n",
       "      <td>5.520205</td>\n",
       "      <td>110.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.629320</td>\n",
       "      <td>0.945962</td>\n",
       "      <td>0.251140</td>\n",
       "      <td>-4.607238</td>\n",
       "      <td>391.628240</td>\n",
       "      <td>33686.667453</td>\n",
       "      <td>5907.975523</td>\n",
       "      <td>-9.875704e+05</td>\n",
       "      <td>1.027165e+06</td>\n",
       "      <td>0.175380</td>\n",
       "      <td>1.990200e+08</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:48:51.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.076254e+06</td>\n",
       "      <td>5.061743e+06</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.139173</td>\n",
       "      <td>1900-11-10 11:40:21</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.102450e+06</td>\n",
       "      <td>6.049472e+06</td>\n",
       "      <td>6.091460e+06</td>\n",
       "      <td>16543.394419</td>\n",
       "      <td>-1.058454</td>\n",
       "      <td>2.345212e+09</td>\n",
       "      <td>385</td>\n",
       "      <td>5.112874e+06</td>\n",
       "      <td>5.042857e+06</td>\n",
       "      <td>5.094050e+06</td>\n",
       "      <td>26764.042729</td>\n",
       "      <td>-0.802446</td>\n",
       "      <td>1.961209e+09</td>\n",
       "      <td>10.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.607922</td>\n",
       "      <td>2.412688</td>\n",
       "      <td>1.590284</td>\n",
       "      <td>619.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>0.637959</td>\n",
       "      <td>-1.303134</td>\n",
       "      <td>231.330402</td>\n",
       "      <td>52978.013345</td>\n",
       "      <td>70016.655842</td>\n",
       "      <td>-9.365979e+05</td>\n",
       "      <td>1.059593e+06</td>\n",
       "      <td>1.321617</td>\n",
       "      <td>3.709343e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:39:47.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6.321032e+06</td>\n",
       "      <td>5.242805e+06</td>\n",
       "      <td>4.48</td>\n",
       "      <td>-0.838671</td>\n",
       "      <td>1900-11-10 11:49:36</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.346913e+06</td>\n",
       "      <td>6.246119e+06</td>\n",
       "      <td>6.262484e+06</td>\n",
       "      <td>32280.567149</td>\n",
       "      <td>1.623040</td>\n",
       "      <td>2.486206e+09</td>\n",
       "      <td>397</td>\n",
       "      <td>5.265810e+06</td>\n",
       "      <td>5.229867e+06</td>\n",
       "      <td>5.242458e+06</td>\n",
       "      <td>5975.460236</td>\n",
       "      <td>2.198003</td>\n",
       "      <td>2.081256e+09</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.313854</td>\n",
       "      <td>2.442825</td>\n",
       "      <td>2.145410</td>\n",
       "      <td>521.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999391</td>\n",
       "      <td>0.350460</td>\n",
       "      <td>0.705955</td>\n",
       "      <td>-0.633320</td>\n",
       "      <td>139.132494</td>\n",
       "      <td>100794.674835</td>\n",
       "      <td>35942.703641</td>\n",
       "      <td>-9.803087e+05</td>\n",
       "      <td>1.117046e+06</td>\n",
       "      <td>0.356593</td>\n",
       "      <td>3.622833e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:33:53.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>6.102751e+06</td>\n",
       "      <td>5.112534e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900-10-30 23:50:05</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-10-30</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.151439e+06</td>\n",
       "      <td>6.102326e+06</td>\n",
       "      <td>6.123711e+06</td>\n",
       "      <td>14451.941954</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>2.516845e+09</td>\n",
       "      <td>411</td>\n",
       "      <td>5.112752e+06</td>\n",
       "      <td>5.069616e+06</td>\n",
       "      <td>5.085480e+06</td>\n",
       "      <td>14020.260117</td>\n",
       "      <td>1.055676</td>\n",
       "      <td>2.090132e+09</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.965864</td>\n",
       "      <td>1.647069</td>\n",
       "      <td>-0.215287</td>\n",
       "      <td>1218.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.981627</td>\n",
       "      <td>0.224864</td>\n",
       "      <td>0.518319</td>\n",
       "      <td>0.053032</td>\n",
       "      <td>92.419078</td>\n",
       "      <td>49113.022232</td>\n",
       "      <td>43135.705758</td>\n",
       "      <td>-9.895740e+05</td>\n",
       "      <td>1.081823e+06</td>\n",
       "      <td>0.878295</td>\n",
       "      <td>2.118525e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:48:47.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>6.843713e+06</td>\n",
       "      <td>5.480538e+06</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>1900-11-06 23:42:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-11-06</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.844414e+06</td>\n",
       "      <td>6.748890e+06</td>\n",
       "      <td>6.807536e+06</td>\n",
       "      <td>26263.537565</td>\n",
       "      <td>-0.770190</td>\n",
       "      <td>2.566441e+09</td>\n",
       "      <td>377</td>\n",
       "      <td>5.540087e+06</td>\n",
       "      <td>5.440815e+06</td>\n",
       "      <td>5.464764e+06</td>\n",
       "      <td>30135.645906</td>\n",
       "      <td>1.412544</td>\n",
       "      <td>2.060216e+09</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.085570</td>\n",
       "      <td>2.649306</td>\n",
       "      <td>1.110173</td>\n",
       "      <td>786.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>0.711243</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>-5.284929</td>\n",
       "      <td>95524.035775</td>\n",
       "      <td>99271.486171</td>\n",
       "      <td>-1.208803e+06</td>\n",
       "      <td>1.403598e+06</td>\n",
       "      <td>1.039230</td>\n",
       "      <td>9.482813e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:37:11.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>995</td>\n",
       "      <td>6.125976e+06</td>\n",
       "      <td>5.106606e+06</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>1900-10-30 23:59:01</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-10-30</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.222693e+06</td>\n",
       "      <td>6.111125e+06</td>\n",
       "      <td>6.194461e+06</td>\n",
       "      <td>37374.830389</td>\n",
       "      <td>-0.991529</td>\n",
       "      <td>2.223812e+09</td>\n",
       "      <td>359</td>\n",
       "      <td>5.120044e+06</td>\n",
       "      <td>5.014167e+06</td>\n",
       "      <td>5.059876e+06</td>\n",
       "      <td>31502.828923</td>\n",
       "      <td>0.712507</td>\n",
       "      <td>1.816496e+09</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.321114</td>\n",
       "      <td>1.689940</td>\n",
       "      <td>0.759014</td>\n",
       "      <td>1192.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.092424</td>\n",
       "      <td>0.770772</td>\n",
       "      <td>-0.219015</td>\n",
       "      <td>33.180228</td>\n",
       "      <td>111567.441251</td>\n",
       "      <td>105877.437402</td>\n",
       "      <td>-9.910811e+05</td>\n",
       "      <td>1.208526e+06</td>\n",
       "      <td>0.948999</td>\n",
       "      <td>1.181247e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:56:57.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>86217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6996</td>\n",
       "      <td>996</td>\n",
       "      <td>6.182685e+06</td>\n",
       "      <td>5.193692e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900-11-20 23:57:37</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-20</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.226342e+06</td>\n",
       "      <td>6.182074e+06</td>\n",
       "      <td>6.188018e+06</td>\n",
       "      <td>11540.064869</td>\n",
       "      <td>1.949834</td>\n",
       "      <td>2.574215e+09</td>\n",
       "      <td>416</td>\n",
       "      <td>5.193694e+06</td>\n",
       "      <td>5.130692e+06</td>\n",
       "      <td>5.187657e+06</td>\n",
       "      <td>13964.337713</td>\n",
       "      <td>-2.405522</td>\n",
       "      <td>2.158065e+09</td>\n",
       "      <td>10.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.976370</td>\n",
       "      <td>1.838527</td>\n",
       "      <td>2.520699</td>\n",
       "      <td>406.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.492420</td>\n",
       "      <td>0.653959</td>\n",
       "      <td>-1.048098</td>\n",
       "      <td>204.846884</td>\n",
       "      <td>44267.650524</td>\n",
       "      <td>63001.952250</td>\n",
       "      <td>-9.883799e+05</td>\n",
       "      <td>1.095650e+06</td>\n",
       "      <td>1.423205</td>\n",
       "      <td>2.788948e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:55:56.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>86156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6997</td>\n",
       "      <td>997</td>\n",
       "      <td>6.093432e+06</td>\n",
       "      <td>5.120416e+06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>1900-11-23 23:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1900-11-23</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>6.093733e+06</td>\n",
       "      <td>6.093328e+06</td>\n",
       "      <td>6.093434e+06</td>\n",
       "      <td>25.328051</td>\n",
       "      <td>10.228469</td>\n",
       "      <td>1.998646e+09</td>\n",
       "      <td>328</td>\n",
       "      <td>5.120416e+06</td>\n",
       "      <td>5.120190e+06</td>\n",
       "      <td>5.120407e+06</td>\n",
       "      <td>34.898016</td>\n",
       "      <td>-4.211072</td>\n",
       "      <td>1.679494e+09</td>\n",
       "      <td>8.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.267378</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>8.049037</td>\n",
       "      <td>87.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999391</td>\n",
       "      <td>0.483434</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>-1.030098</td>\n",
       "      <td>158.566261</td>\n",
       "      <td>404.863211</td>\n",
       "      <td>226.309553</td>\n",
       "      <td>-9.729118e+05</td>\n",
       "      <td>9.735430e+05</td>\n",
       "      <td>0.558978</td>\n",
       "      <td>9.162441e+04</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 11:44:32.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>42272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6998</td>\n",
       "      <td>998</td>\n",
       "      <td>6.102849e+06</td>\n",
       "      <td>5.112313e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900-11-06 23:51:34</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-06</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>6.102851e+06</td>\n",
       "      <td>6.102849e+06</td>\n",
       "      <td>6.102849e+06</td>\n",
       "      <td>0.334371</td>\n",
       "      <td>5.800348</td>\n",
       "      <td>2.441140e+09</td>\n",
       "      <td>400</td>\n",
       "      <td>5.112422e+06</td>\n",
       "      <td>5.112313e+06</td>\n",
       "      <td>5.112316e+06</td>\n",
       "      <td>17.841769</td>\n",
       "      <td>5.800348</td>\n",
       "      <td>2.044926e+09</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.133787</td>\n",
       "      <td>7.743118</td>\n",
       "      <td>16.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325568</td>\n",
       "      <td>0.996180</td>\n",
       "      <td>0.047528</td>\n",
       "      <td>-13.683144</td>\n",
       "      <td>398.472140</td>\n",
       "      <td>2.042086</td>\n",
       "      <td>108.964045</td>\n",
       "      <td>-9.904269e+05</td>\n",
       "      <td>9.905379e+05</td>\n",
       "      <td>53.359189</td>\n",
       "      <td>2.225139e+02</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2 days 23:49:48.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6999</td>\n",
       "      <td>999</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900-11-03 11:52:58</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-11-03</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>6.138412e+06</td>\n",
       "      <td>6.138413e+06</td>\n",
       "      <td>0.881331</td>\n",
       "      <td>-0.485474</td>\n",
       "      <td>2.246659e+09</td>\n",
       "      <td>366</td>\n",
       "      <td>5.162715e+06</td>\n",
       "      <td>5.162606e+06</td>\n",
       "      <td>5.162673e+06</td>\n",
       "      <td>53.118092</td>\n",
       "      <td>-0.485474</td>\n",
       "      <td>1.889538e+09</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.145273</td>\n",
       "      <td>0.199444</td>\n",
       "      <td>9.123419</td>\n",
       "      <td>53.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>0.409065</td>\n",
       "      <td>0.742263</td>\n",
       "      <td>-0.781595</td>\n",
       "      <td>149.717739</td>\n",
       "      <td>1.810955</td>\n",
       "      <td>109.146850</td>\n",
       "      <td>-9.756968e+05</td>\n",
       "      <td>9.758078e+05</td>\n",
       "      <td>60.270332</td>\n",
       "      <td>1.976600e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2 days 23:44:59.000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>85499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ship             x             y     v         d                 time  \\\n",
       "0        0  6.152038e+06  5.124873e+06  2.59 -0.207912  1900-11-10 11:58:19   \n",
       "1        1  6.076254e+06  5.061743e+06  3.99  0.139173  1900-11-10 11:40:21   \n",
       "2       10  6.321032e+06  5.242805e+06  4.48 -0.838671  1900-11-10 11:49:36   \n",
       "3      100  6.102751e+06  5.112534e+06  0.00  1.000000  1900-10-30 23:50:05   \n",
       "4     1000  6.843713e+06  5.480538e+06  2.00 -0.809017  1900-11-06 23:42:30   \n",
       "...    ...           ...           ...   ...       ...                  ...   \n",
       "6995   995  6.125976e+06  5.106606e+06  3.78  0.484810  1900-10-30 23:59:01   \n",
       "6996   996  6.182685e+06  5.193692e+06  0.11  1.000000  1900-11-20 23:57:37   \n",
       "6997   997  6.093432e+06  5.120416e+06  0.32  0.743145  1900-11-23 23:50:00   \n",
       "6998   998  6.102849e+06  5.112313e+06  0.00  1.000000  1900-11-06 23:51:34   \n",
       "6999   999  6.138413e+06  5.162715e+06  0.11  1.000000  1900-11-03 11:52:58   \n",
       "\n",
       "      type        date  hour  weekday         x_max         x_min  \\\n",
       "0        0  1900-11-10    11        5  6.152038e+06  6.118352e+06   \n",
       "1        0  1900-11-10    11        5  6.102450e+06  6.049472e+06   \n",
       "2        0  1900-11-10    11        5  6.346913e+06  6.246119e+06   \n",
       "3        0  1900-10-30    23        1  6.151439e+06  6.102326e+06   \n",
       "4        1  1900-11-06    23        1  6.844414e+06  6.748890e+06   \n",
       "...    ...         ...   ...      ...           ...           ...   \n",
       "6995     0  1900-10-30    23        1  6.222693e+06  6.111125e+06   \n",
       "6996     0  1900-11-20    23        1  6.226342e+06  6.182074e+06   \n",
       "6997     2  1900-11-23    23        4  6.093733e+06  6.093328e+06   \n",
       "6998     0  1900-11-06    23        1  6.102851e+06  6.102849e+06   \n",
       "6999     0  1900-11-03    11        5  6.138413e+06  6.138412e+06   \n",
       "\n",
       "            x_mean         x_std     x_skew         x_sum  x_count  \\\n",
       "0     6.119351e+06   5037.320747   5.255558  2.533411e+09      414   \n",
       "1     6.091460e+06  16543.394419  -1.058454  2.345212e+09      385   \n",
       "2     6.262484e+06  32280.567149   1.623040  2.486206e+09      397   \n",
       "3     6.123711e+06  14451.941954   0.021860  2.516845e+09      411   \n",
       "4     6.807536e+06  26263.537565  -0.770190  2.566441e+09      377   \n",
       "...            ...           ...        ...           ...      ...   \n",
       "6995  6.194461e+06  37374.830389  -0.991529  2.223812e+09      359   \n",
       "6996  6.188018e+06  11540.064869   1.949834  2.574215e+09      416   \n",
       "6997  6.093434e+06     25.328051  10.228469  1.998646e+09      328   \n",
       "6998  6.102849e+06      0.334371   5.800348  2.441140e+09      400   \n",
       "6999  6.138413e+06      0.881331  -0.485474  2.246659e+09      366   \n",
       "\n",
       "             y_max         y_min        y_mean         y_std    y_skew  \\\n",
       "0     5.130781e+06  5.124873e+06  5.130494e+06    850.264541 -4.762308   \n",
       "1     5.112874e+06  5.042857e+06  5.094050e+06  26764.042729 -0.802446   \n",
       "2     5.265810e+06  5.229867e+06  5.242458e+06   5975.460236  2.198003   \n",
       "3     5.112752e+06  5.069616e+06  5.085480e+06  14020.260117  1.055676   \n",
       "4     5.540087e+06  5.440815e+06  5.464764e+06  30135.645906  1.412544   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "6995  5.120044e+06  5.014167e+06  5.059876e+06  31502.828923  0.712507   \n",
       "6996  5.193694e+06  5.130692e+06  5.187657e+06  13964.337713 -2.405522   \n",
       "6997  5.120416e+06  5.120190e+06  5.120407e+06     34.898016 -4.211072   \n",
       "6998  5.112422e+06  5.112313e+06  5.112316e+06     17.841769  5.800348   \n",
       "6999  5.162715e+06  5.162606e+06  5.162673e+06     53.118092 -0.485474   \n",
       "\n",
       "             y_sum  v_max  v_min    v_mean     v_std    v_skew    v_sum  \\\n",
       "0     2.124025e+09   9.39   0.00  0.265966  1.321248  5.520205   110.11   \n",
       "1     1.961209e+09  10.47   0.00  1.607922  2.412688  1.590284   619.05   \n",
       "2     2.081256e+09  10.09   0.00  1.313854  2.442825  2.145410   521.60   \n",
       "3     2.090132e+09   8.69   0.00  2.965864  1.647069 -0.215287  1218.97   \n",
       "4     2.060216e+09   8.90   0.00  2.085570  2.649306  1.110173   786.26   \n",
       "...            ...    ...    ...       ...       ...       ...      ...   \n",
       "6995  1.816496e+09  10.09   0.11  3.321114  1.689940  0.759014  1192.28   \n",
       "6996  2.158065e+09  10.09   0.00  0.976370  1.838527  2.520699   406.17   \n",
       "6997  1.679494e+09   8.31   0.00  0.267378  0.866750  8.049037    87.70   \n",
       "6998  2.044926e+09   1.57   0.00  0.040175  0.133787  7.743118    16.07   \n",
       "6999  1.889538e+09   3.08   0.00  0.145273  0.199444  9.123419    53.17   \n",
       "\n",
       "      d_max     d_min    d_mean     d_std     d_skew       d_sum  \\\n",
       "0       1.0 -0.629320  0.945962  0.251140  -4.607238  391.628240   \n",
       "1       1.0 -0.999848  0.600858  0.637959  -1.303134  231.330402   \n",
       "2       1.0 -0.999391  0.350460  0.705955  -0.633320  139.132494   \n",
       "3       1.0 -0.981627  0.224864  0.518319   0.053032   92.419078   \n",
       "4       1.0 -0.999848 -0.014018  0.711243   0.056856   -5.284929   \n",
       "...     ...       ...       ...       ...        ...         ...   \n",
       "6995    1.0 -1.000000  0.092424  0.770772  -0.219015   33.180228   \n",
       "6996    1.0 -1.000000  0.492420  0.653959  -1.048098  204.846884   \n",
       "6997    1.0 -0.999391  0.483434  0.710951  -1.030098  158.566261   \n",
       "6998    1.0  0.325568  0.996180  0.047528 -13.683144  398.472140   \n",
       "6999    1.0 -0.999848  0.409065  0.742263  -0.781595  149.717739   \n",
       "\n",
       "        x_max_x_min    y_max_y_min   y_max_x_min   x_max_y_min      slope  \\\n",
       "0      33686.667453    5907.975523 -9.875704e+05  1.027165e+06   0.175380   \n",
       "1      52978.013345   70016.655842 -9.365979e+05  1.059593e+06   1.321617   \n",
       "2     100794.674835   35942.703641 -9.803087e+05  1.117046e+06   0.356593   \n",
       "3      49113.022232   43135.705758 -9.895740e+05  1.081823e+06   0.878295   \n",
       "4      95524.035775   99271.486171 -1.208803e+06  1.403598e+06   1.039230   \n",
       "...             ...            ...           ...           ...        ...   \n",
       "6995  111567.441251  105877.437402 -9.910811e+05  1.208526e+06   0.948999   \n",
       "6996   44267.650524   63001.952250 -9.883799e+05  1.095650e+06   1.423205   \n",
       "6997     404.863211     226.309553 -9.729118e+05  9.735430e+05   0.558978   \n",
       "6998       2.042086     108.964045 -9.904269e+05  9.905379e+05  53.359189   \n",
       "6999       1.810955     109.146850 -9.756968e+05  9.758078e+05  60.270332   \n",
       "\n",
       "              area  mode_hour  hour_max  hour_min  hour_nunique  date_nunique  \\\n",
       "0     1.990200e+08         15        23         0            24             4   \n",
       "1     3.709343e+09         19        23         0            24             4   \n",
       "2     3.622833e+09         23        23         0            24             4   \n",
       "3     2.118525e+09         11        23         0            24             3   \n",
       "4     9.482813e+09          0        23         0            24             3   \n",
       "...            ...        ...       ...       ...           ...           ...   \n",
       "6995  1.181247e+10          1        23         0            24             3   \n",
       "6996  2.788948e+09          8        23         0            24             3   \n",
       "6997  9.162441e+04         22        23         0            24             3   \n",
       "6998  2.225139e+02         23        23         0            24             3   \n",
       "6999  1.976600e+02          0        23         0            24             4   \n",
       "\n",
       "                      diff_time  diff_day  diff_second  \n",
       "0     2 days 23:48:51.000000000         2        85731  \n",
       "1     2 days 23:39:47.000000000         2        85187  \n",
       "2     2 days 23:33:53.000000000         2        84833  \n",
       "3     2 days 23:48:47.000000000         2        85727  \n",
       "4     2 days 23:37:11.000000000         2        85031  \n",
       "...                         ...       ...          ...  \n",
       "6995  2 days 23:56:57.000000000         2        86217  \n",
       "6996  2 days 23:55:56.000000000         2        86156  \n",
       "6997  2 days 11:44:32.000000000         2        42272  \n",
       "6998  2 days 23:49:48.000000000         2        85788  \n",
       "6999  2 days 23:44:59.000000000         2        85499  \n",
       "\n",
       "[7000 rows x 49 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:48:05.283202Z",
     "start_time": "2020-02-09T05:48:05.197585Z"
    }
   },
   "outputs": [],
   "source": [
    "data_bin = pd.read_csv(r\"E:\\jupyter\\智慧海洋\\tianchi_ship_2019-master\\working\\复现代码\\temp\\/binfea/bin_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:48:10.642339Z",
     "start_time": "2020-02-09T05:48:10.608918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_0</th>\n",
       "      <th>cut_1</th>\n",
       "      <th>cut_2</th>\n",
       "      <th>cut_3</th>\n",
       "      <th>cut_4</th>\n",
       "      <th>cut_5</th>\n",
       "      <th>cut_6</th>\n",
       "      <th>cut_7</th>\n",
       "      <th>cut_8</th>\n",
       "      <th>cut_9</th>\n",
       "      <th>cut_10</th>\n",
       "      <th>cut_11</th>\n",
       "      <th>cut_12</th>\n",
       "      <th>cut_13</th>\n",
       "      <th>cut_14</th>\n",
       "      <th>cut_v_0</th>\n",
       "      <th>cut_v_1</th>\n",
       "      <th>cut_v_2</th>\n",
       "      <th>cut_v_3</th>\n",
       "      <th>cut_v_4</th>\n",
       "      <th>cut_v_5</th>\n",
       "      <th>cut_v_6</th>\n",
       "      <th>cut_v_7</th>\n",
       "      <th>cut_v_8</th>\n",
       "      <th>cut_v_9</th>\n",
       "      <th>cut_v_10</th>\n",
       "      <th>cut_v_11</th>\n",
       "      <th>cut_v_12</th>\n",
       "      <th>cut_v_13</th>\n",
       "      <th>cut_v_14</th>\n",
       "      <th>cut_d_0</th>\n",
       "      <th>cut_d_1</th>\n",
       "      <th>cut_d_2</th>\n",
       "      <th>cut_d_3</th>\n",
       "      <th>cut_d_4</th>\n",
       "      <th>cut_d_5</th>\n",
       "      <th>cut_d_6</th>\n",
       "      <th>cut_d_7</th>\n",
       "      <th>cut_d_8</th>\n",
       "      <th>cut_d_9</th>\n",
       "      <th>cut_d_10</th>\n",
       "      <th>cut_d_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.062802</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.306494</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.132468</td>\n",
       "      <td>0.096104</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644156</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231760</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.094421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.483582</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394030</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.101493</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.032836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.152120</td>\n",
       "      <td>0.618454</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>248</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264339</td>\n",
       "      <td>0.092269</td>\n",
       "      <td>0.084788</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.067332</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.052369</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8995</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203297</td>\n",
       "      <td>0.052198</td>\n",
       "      <td>0.049451</td>\n",
       "      <td>0.090659</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.049451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8996</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>0.094183</td>\n",
       "      <td>0.357341</td>\n",
       "      <td>0.260388</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.038781</td>\n",
       "      <td>0.038781</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>129</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196676</td>\n",
       "      <td>0.083102</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.138504</td>\n",
       "      <td>0.243767</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.080332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8997</td>\n",
       "      <td>0.317280</td>\n",
       "      <td>0.682720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8998</td>\n",
       "      <td>0.138973</td>\n",
       "      <td>0.389728</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>0.087613</td>\n",
       "      <td>0.126888</td>\n",
       "      <td>0.081571</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.024169</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.057402</td>\n",
       "      <td>0.024169</td>\n",
       "      <td>0.039275</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>0.081571</td>\n",
       "      <td>0.123867</td>\n",
       "      <td>0.181269</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>0.048338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8999</td>\n",
       "      <td>0.660477</td>\n",
       "      <td>0.339523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978780</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cut_0     cut_1     cut_2     cut_3     cut_4     cut_5     cut_6  \\\n",
       "0     0.891304  0.062802  0.002415  0.009662  0.009662  0.000000  0.000000   \n",
       "1     0.340260  0.306494  0.005195  0.054545  0.132468  0.096104  0.018182   \n",
       "2     0.231760  0.703863  0.017167  0.012876  0.021459  0.004292  0.000000   \n",
       "3     0.208955  0.483582  0.050746  0.068657  0.065672  0.029851  0.023881   \n",
       "4     0.152120  0.618454  0.042394  0.017456  0.007481  0.014963  0.047382   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8995  0.104396  0.576923  0.082418  0.041209  0.024725  0.005495  0.010989   \n",
       "8996  0.005540  0.108033  0.094183  0.357341  0.260388  0.033241  0.024931   \n",
       "8997  0.317280  0.682720  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8998  0.138973  0.389728  0.072508  0.087613  0.126888  0.081571  0.018127   \n",
       "8999  0.660477  0.339523  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         cut_7     cut_8     cut_9    cut_10    cut_11  cut_12  cut_13  \\\n",
       "0     0.002415  0.004831  0.014493  0.002415  0.000000     0.0     0.0   \n",
       "1     0.005195  0.000000  0.012987  0.015584  0.012987     0.0     0.0   \n",
       "2     0.004292  0.000000  0.004292  0.000000  0.000000     0.0     0.0   \n",
       "3     0.000000  0.005970  0.014925  0.029851  0.017910     0.0     0.0   \n",
       "4     0.032419  0.034913  0.022444  0.007481  0.002494     0.0     0.0   \n",
       "...        ...       ...       ...       ...       ...     ...     ...   \n",
       "8995  0.005495  0.016484  0.005495  0.021978  0.104396     0.0     0.0   \n",
       "8996  0.005540  0.038781  0.038781  0.016620  0.016620     0.0     0.0   \n",
       "8997  0.000000  0.000000  0.000000  0.000000  0.000000     0.0     0.0   \n",
       "8998  0.024169  0.015106  0.027190  0.015106  0.003021     0.0     0.0   \n",
       "8999  0.000000  0.000000  0.000000  0.000000  0.000000     0.0     0.0   \n",
       "\n",
       "      cut_14  cut_v_0  cut_v_1  cut_v_2  cut_v_3  cut_v_4  cut_v_5  cut_v_6  \\\n",
       "0        0.0      369       26        1        4        4        0        0   \n",
       "1        0.0      131      118        2       21       51       37        7   \n",
       "2        0.0       54      164        4        3        5        1        0   \n",
       "3        0.0       70      162       17       23       22       10        8   \n",
       "4        0.0       61      248       17        7        3        6       19   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "8995     0.0       38      210       30       15        9        2        4   \n",
       "8996     0.0        2       39       34      129       94       12        9   \n",
       "8997     0.0      112      241        0        0        0        0        0   \n",
       "8998     0.0       46      129       24       29       42       27        6   \n",
       "8999     0.0      249      128        0        0        0        0        0   \n",
       "\n",
       "      cut_v_7  cut_v_8  cut_v_9  cut_v_10  cut_v_11  cut_v_12  cut_v_13  \\\n",
       "0           1        2        6         1         0         0         0   \n",
       "1           2        0        5         6         5         0         0   \n",
       "2           1        0        1         0         0         0         0   \n",
       "3           0        2        5        10         6         0         0   \n",
       "4          13       14        9         3         1         0         0   \n",
       "...       ...      ...      ...       ...       ...       ...       ...   \n",
       "8995        2        6        2         8        38         0         0   \n",
       "8996        2       14       14         6         6         0         0   \n",
       "8997        0        0        0         0         0         0         0   \n",
       "8998        8        5        9         5         1         0         0   \n",
       "8999        0        0        0         0         0         0         0   \n",
       "\n",
       "      cut_v_14   cut_d_0   cut_d_1   cut_d_2   cut_d_3   cut_d_4   cut_d_5  \\\n",
       "0            0  0.954106  0.000000  0.009662  0.033816  0.002415  0.000000   \n",
       "1            0  0.644156  0.070130  0.059740  0.031169  0.007792  0.007792   \n",
       "2            0  0.313305  0.133047  0.085837  0.055794  0.060086  0.042918   \n",
       "3            0  0.394030  0.026866  0.053731  0.104478  0.053731  0.038806   \n",
       "4            0  0.264339  0.092269  0.084788  0.072319  0.054863  0.032419   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8995         0  0.203297  0.052198  0.049451  0.090659  0.065934  0.096154   \n",
       "8996         0  0.196676  0.083102  0.041551  0.022161  0.030471  0.060942   \n",
       "8997         0  0.974504  0.008499  0.002833  0.002833  0.000000  0.005666   \n",
       "8998         0  0.320242  0.057402  0.024169  0.039275  0.051360  0.081571   \n",
       "8999         0  0.978780  0.002653  0.002653  0.002653  0.002653  0.000000   \n",
       "\n",
       "       cut_d_6   cut_d_7   cut_d_8   cut_d_9  cut_d_10  cut_d_11  \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.033766  0.062338  0.070130  0.005195  0.002597  0.005195  \n",
       "2     0.025751  0.038627  0.047210  0.051502  0.047210  0.094421  \n",
       "3     0.029851  0.029851  0.059701  0.101493  0.074627  0.032836  \n",
       "4     0.064838  0.067332  0.074813  0.039900  0.052369  0.099751  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "8995  0.046703  0.046703  0.131868  0.107143  0.060440  0.049451  \n",
       "8996  0.138504  0.243767  0.052632  0.008310  0.041551  0.080332  \n",
       "8997  0.000000  0.000000  0.000000  0.002833  0.000000  0.002833  \n",
       "8998  0.123867  0.181269  0.030211  0.021148  0.021148  0.048338  \n",
       "8999  0.000000  0.002653  0.005305  0.000000  0.000000  0.002653  \n",
       "\n",
       "[9000 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T05:49:28.134104Z",
     "start_time": "2020-02-09T05:49:28.107149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut_0</th>\n",
       "      <th>cut_1</th>\n",
       "      <th>cut_2</th>\n",
       "      <th>cut_3</th>\n",
       "      <th>cut_4</th>\n",
       "      <th>cut_5</th>\n",
       "      <th>cut_6</th>\n",
       "      <th>cut_7</th>\n",
       "      <th>cut_8</th>\n",
       "      <th>cut_9</th>\n",
       "      <th>cut_10</th>\n",
       "      <th>cut_11</th>\n",
       "      <th>cut_12</th>\n",
       "      <th>cut_13</th>\n",
       "      <th>cut_14</th>\n",
       "      <th>cut_v_0</th>\n",
       "      <th>cut_v_1</th>\n",
       "      <th>cut_v_2</th>\n",
       "      <th>cut_v_3</th>\n",
       "      <th>cut_v_4</th>\n",
       "      <th>cut_v_5</th>\n",
       "      <th>cut_v_6</th>\n",
       "      <th>cut_v_7</th>\n",
       "      <th>cut_v_8</th>\n",
       "      <th>cut_v_9</th>\n",
       "      <th>cut_v_10</th>\n",
       "      <th>cut_v_11</th>\n",
       "      <th>cut_v_12</th>\n",
       "      <th>cut_v_13</th>\n",
       "      <th>cut_v_14</th>\n",
       "      <th>cut_d_0</th>\n",
       "      <th>cut_d_1</th>\n",
       "      <th>cut_d_2</th>\n",
       "      <th>cut_d_3</th>\n",
       "      <th>cut_d_4</th>\n",
       "      <th>cut_d_5</th>\n",
       "      <th>cut_d_6</th>\n",
       "      <th>cut_d_7</th>\n",
       "      <th>cut_d_8</th>\n",
       "      <th>cut_d_9</th>\n",
       "      <th>cut_d_10</th>\n",
       "      <th>cut_d_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.062802</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.306494</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.132468</td>\n",
       "      <td>0.096104</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644156</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231760</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.094421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.483582</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.068657</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394030</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.101493</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.032836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.152120</td>\n",
       "      <td>0.618454</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.022444</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>248</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264339</td>\n",
       "      <td>0.092269</td>\n",
       "      <td>0.084788</td>\n",
       "      <td>0.072319</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.032419</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.067332</td>\n",
       "      <td>0.074813</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.052369</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cut_0     cut_1     cut_2     cut_3     cut_4     cut_5     cut_6  \\\n",
       "0  0.891304  0.062802  0.002415  0.009662  0.009662  0.000000  0.000000   \n",
       "1  0.340260  0.306494  0.005195  0.054545  0.132468  0.096104  0.018182   \n",
       "2  0.231760  0.703863  0.017167  0.012876  0.021459  0.004292  0.000000   \n",
       "3  0.208955  0.483582  0.050746  0.068657  0.065672  0.029851  0.023881   \n",
       "4  0.152120  0.618454  0.042394  0.017456  0.007481  0.014963  0.047382   \n",
       "\n",
       "      cut_7     cut_8     cut_9    cut_10    cut_11  cut_12  cut_13  cut_14  \\\n",
       "0  0.002415  0.004831  0.014493  0.002415  0.000000     0.0     0.0     0.0   \n",
       "1  0.005195  0.000000  0.012987  0.015584  0.012987     0.0     0.0     0.0   \n",
       "2  0.004292  0.000000  0.004292  0.000000  0.000000     0.0     0.0     0.0   \n",
       "3  0.000000  0.005970  0.014925  0.029851  0.017910     0.0     0.0     0.0   \n",
       "4  0.032419  0.034913  0.022444  0.007481  0.002494     0.0     0.0     0.0   \n",
       "\n",
       "   cut_v_0  cut_v_1  cut_v_2  cut_v_3  cut_v_4  cut_v_5  cut_v_6  cut_v_7  \\\n",
       "0      369       26        1        4        4        0        0        1   \n",
       "1      131      118        2       21       51       37        7        2   \n",
       "2       54      164        4        3        5        1        0        1   \n",
       "3       70      162       17       23       22       10        8        0   \n",
       "4       61      248       17        7        3        6       19       13   \n",
       "\n",
       "   cut_v_8  cut_v_9  cut_v_10  cut_v_11  cut_v_12  cut_v_13  cut_v_14  \\\n",
       "0        2        6         1         0         0         0         0   \n",
       "1        0        5         6         5         0         0         0   \n",
       "2        0        1         0         0         0         0         0   \n",
       "3        2        5        10         6         0         0         0   \n",
       "4       14        9         3         1         0         0         0   \n",
       "\n",
       "    cut_d_0   cut_d_1   cut_d_2   cut_d_3   cut_d_4   cut_d_5   cut_d_6  \\\n",
       "0  0.954106  0.000000  0.009662  0.033816  0.002415  0.000000  0.000000   \n",
       "1  0.644156  0.070130  0.059740  0.031169  0.007792  0.007792  0.033766   \n",
       "2  0.313305  0.133047  0.085837  0.055794  0.060086  0.042918  0.025751   \n",
       "3  0.394030  0.026866  0.053731  0.104478  0.053731  0.038806  0.029851   \n",
       "4  0.264339  0.092269  0.084788  0.072319  0.054863  0.032419  0.064838   \n",
       "\n",
       "    cut_d_7   cut_d_8   cut_d_9  cut_d_10  cut_d_11  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.062338  0.070130  0.005195  0.002597  0.005195  \n",
       "2  0.038627  0.047210  0.051502  0.047210  0.094421  \n",
       "3  0.029851  0.059701  0.101493  0.074627  0.032836  \n",
       "4  0.067332  0.074813  0.039900  0.052369  0.099751  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_fea  = ['cut_0', 'cut_1',\n",
    "       'cut_2', 'cut_3', 'cut_4', 'cut_5', 'cut_6', 'cut_7', 'cut_8', 'cut_9',\n",
    "       'cut_10', 'cut_11', 'cut_12', 'cut_13', 'cut_14', 'cut_v_0', 'cut_v_1',\n",
    "       'cut_v_2', 'cut_v_3', 'cut_v_4', 'cut_v_5', 'cut_v_6', 'cut_v_7',\n",
    "       'cut_v_8', 'cut_v_9', 'cut_v_10', 'cut_v_11', 'cut_v_12', 'cut_v_13',\n",
    "       'cut_v_14', 'cut_d_0', 'cut_d_1', 'cut_d_2', 'cut_d_3', 'cut_d_4',\n",
    "       'cut_d_5', 'cut_d_6', 'cut_d_7', 'cut_d_8', 'cut_d_9', 'cut_d_10',\n",
    "       'cut_d_11',]\n",
    "data[bin_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y   2\n",
    "x   2\n",
    "v  5\n",
    "d  3\n",
    "x-y\n",
    "v-d\n",
    "label-v\n",
    "date\n",
    "label-date\n",
    "x-y-v\n",
    "date-v\n",
    "x-y-v-1000\n",
    "\n",
    "w2c_d.csv\n",
    "w2c_date-v.csv\n",
    "w2c_date.csv\n",
    "w2c_label-v.csv\n",
    "w2c_v-d.csv\n",
    "w2c_v.csv\n",
    "w2c_x-100.csv\n",
    "w2c_x-y-v-1000.csv\n",
    "w2c_x-y.csv\n",
    "w2c_y-100.csv\n",
    "\n",
    "\n",
    "label-date\n",
    "x-y-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T01:58:10.412155Z",
     "start_time": "2020-02-18T01:58:08.399851Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data ={}\n",
    "root_path = \"./submit/submit_stack/\"\n",
    "for i in os.listdir(root_path):\n",
    "    data[i]  = pd.read_csv(root_path+i,header=None)[1]\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "submit = pd.read_csv(root_path+i,header=None)\n",
    "x = data.apply(lambda x:len(x[x==\"刺网\"]),axis=1)\n",
    "\n",
    "submit[1] = data.mode(axis=1)\n",
    "submit[x>=2] =\"刺网\"\n",
    "submit.to_csv(\"./submit/stack2.csv\",index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T01:55:40.759251Z",
     "start_time": "2020-02-18T01:55:39.792750Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T02:13:19.356683Z",
     "start_time": "2020-02-18T02:13:19.348183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((257,), (249,), (245,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x>=1].shape,x[x>=2].shape,x[x>=3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T01:56:02.109459Z",
     "start_time": "2020-02-18T01:56:01.865113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.743e+03, 0.000e+00, 8.000e+00, 0.000e+00, 4.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 3.000e+00, 2.410e+02]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T01:53:03.643299Z",
     "start_time": "2020-02-18T01:53:03.637314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result_0.92958_2020-02-17-09-26-28.csv',\n",
       " 'result_0.93056_2020-02-17-10-49-33.csv',\n",
       " 'result_0.93136_2020-02-17-10-21-00.csv',\n",
       " 'result_0.93238_2020-02-17-09-53-07.csv',\n",
       " 'result_0.93275_2020-02-17-11-18-44.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T07:17:14.486064Z",
     "start_time": "2020-02-26T07:17:14.477008Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import train\n",
    "from get_all_feature import output_finally_feature,get_feature,get_fold_index\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from config import config\n",
    "config = config()\n",
    "\n",
    "os.makedirs(\"./log\",exist_ok=1)\n",
    "class Logger(object):\n",
    "    def __init__(self, fileN=\"Default.log\"):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(fileN, \"w\")\n",
    " \n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    " \n",
    "    def flush(self):\n",
    "        pass\n",
    " \n",
    "# sys.stdout = Logger(\"./log/\"+time.strftime('%Y-%m-%d-%H-%M-%S')+\".txt\")\n",
    "\n",
    "def train_model():\n",
    "    # 整理特征\n",
    "    output_finally_feature()\n",
    "    # 打开数据\n",
    "    feature_path = \"./temp/finally_feature/\"\n",
    "    train_label=pd.read_csv(feature_path+\"train_label_88.csv\")\n",
    "    test_label=pd.read_csv(feature_path+\"test_label_88.csv\")\n",
    "    # 获取X，y标签\n",
    "    features,target= get_feature()\n",
    "    # 按地理编码五折\n",
    "    index_list,index_list_val = get_fold_index(train_label,test_label)\n",
    "    # 训练\n",
    "    train(index_list,index_list_val,train_label,test_label,features,target)\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T07:17:15.306067Z",
     "start_time": "2020-02-26T07:17:15.295068Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_all_feature import generalID\n",
    "def output_finally_feature2(name):\n",
    "    \n",
    "\n",
    "    ##########################  基础特征   ########################################\n",
    "    feature_path = \"./temp/basefea/\"\n",
    "    model_result[\"basefeature_path\"] =feature_path\n",
    "    train_label=pd.read_csv( feature_path+\"train_label.csv\")\n",
    "    test_label=pd.read_csv( feature_path+\"test_label.csv\")\n",
    "\n",
    "\n",
    "    ##########################  w2v特征   ########################################\n",
    "    root_path = \"./temp/w2v/\"\n",
    "    for i in name:\n",
    "        print(i)\n",
    "        feature = pd.read_csv(root_path +i)\n",
    "        train_label = pd.merge(train_label,feature,how=\"left\",on=\"ship\")\n",
    "        test_label = pd.merge(test_label,feature,how=\"left\",on=\"ship\")\n",
    "\n",
    "    ##########################  分箱特征   ########################################\n",
    "    bin_feature_save_path = \"./temp/binfea/\"\n",
    "    \n",
    "    train_feature = pd.read_csv(bin_feature_save_path+\"bin_feature_train.csv\")\n",
    "    test_feature= pd.read_csv(bin_feature_save_path+\"bin_feature_test.csv\")\n",
    "    train_label = pd.merge(train_label,train_feature,how=\"left\",on=\"ship\")\n",
    "    test_label = pd.merge(test_label,test_feature,how=\"left\",on=\"ship\")\n",
    "    ##########################  输出   ########################################\n",
    "    feature_path = \"./temp/finally_feature/\"\n",
    "    os.makedirs(feature_path,exist_ok=1)\n",
    "\n",
    "\n",
    "    data =pd.concat([train_label,test_label])\n",
    "    data[\"x\"] = data[\"x\"]*1000\n",
    "    data[\"y\"] = data[\"y\"]*1000\n",
    "    LON1 = np.min(test_label.x)-1\n",
    "    LON2 = np.max(test_label.x)+1\n",
    "    LAT1 = np.min(test_label.y)-1\n",
    "    LAT2 = np.max(test_label.y)+1\n",
    "    data['geoid'] = data.apply(lambda x: generalID(x['x_mean'], x['y_mean'],10,10,LON1,LON2,LAT1,LAT2), axis = 1)\n",
    "    train_label = pd.merge(train_label,data[[\"ship\",\"geoid\"]],how=\"left\",on=\"ship\")\n",
    "    test_label = pd.merge(test_label,data[[\"ship\",\"geoid\"]],how=\"left\",on=\"ship\")\n",
    "    # train_label,test_label = add_geoid(train_label,test_label)\n",
    "\n",
    "    train_label.to_csv(feature_path+\"train_label_88.csv\",index=None)\n",
    "    test_label.to_csv(feature_path+\"test_label_88.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T07:17:34.472408Z",
     "start_time": "2020-02-26T07:17:34.468409Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "root_path = \"./temp/w2v/\"\n",
    "l = os.listdir(root_path)\n",
    "# l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:40:33.088975Z",
     "start_time": "2020-02-26T07:17:35.059922Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------ w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's focal_loss: 0.00211877\tvalid_1's focal_loss: 0.0143082\n",
      "0 val f1 0.9131796840207217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.96      0.95       709\n",
      "           2       0.92      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's focal_loss: 0.00210154\tvalid_1's focal_loss: 0.0140872\n",
      "1 val f1 0.9236075878008907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.95      0.81      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's focal_loss: 0.00296704\tvalid_1's focal_loss: 0.0154605\n",
      "2 val f1 0.9142733373317666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       658\n",
      "           1       0.94      0.97      0.95       708\n",
      "           2       0.92      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's focal_loss: 0.00355137\tvalid_1's focal_loss: 0.0164379\n",
      "3 val f1 0.9080423255148938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.92      0.77      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's focal_loss: 0.00401878\tvalid_1's focal_loss: 0.0157066\n",
      "4 val f1 0.9207126979248628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.93      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.94      1632\n",
      "   macro avg       0.94      0.91      0.92      1632\n",
      "weighted avg       0.94      0.94      0.94      1632\n",
      "\n",
      "oof f1 0.9159898385414591\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91599_2020-02-26-15-21-34\n",
      "围网 oof f1 0.9509371554575523\n",
      "------------------------------------------------ w2c_date-v.csv\n",
      "w2c_d.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's focal_loss: 0.00194523\tvalid_1's focal_loss: 0.0143817\n",
      "0 val f1 0.9148487398576651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's focal_loss: 0.00153201\tvalid_1's focal_loss: 0.0139411\n",
      "1 val f1 0.9252013165706888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.94      0.82      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's focal_loss: 0.00178978\tvalid_1's focal_loss: 0.0147181\n",
      "2 val f1 0.9202740637950194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.94      0.97      0.95       708\n",
      "           2       0.93      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.94      1633\n",
      "   macro avg       0.94      0.91      0.92      1633\n",
      "weighted avg       0.94      0.94      0.94      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's focal_loss: 0.00294384\tvalid_1's focal_loss: 0.0162979\n",
      "3 val f1 0.9115639583883669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.76      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's focal_loss: 0.00343743\tvalid_1's focal_loss: 0.0151723\n",
      "4 val f1 0.9163776123283375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.91769816222518\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.9177_2020-02-26-15-26-37\n",
      "围网 oof f1 0.953168044077135\n",
      "------------------------------------------------ w2c_date.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's focal_loss: 0.00147896\tvalid_1's focal_loss: 0.0141398\n",
      "0 val f1 0.9112672229015719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.00215797\tvalid_1's focal_loss: 0.0135587\n",
      "1 val f1 0.9257555896794201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.82      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's focal_loss: 0.00303597\tvalid_1's focal_loss: 0.0155271\n",
      "2 val f1 0.9155218478131021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.92      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's focal_loss: 0.0034841\tvalid_1's focal_loss: 0.0161058\n",
      "3 val f1 0.9067424488793815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.91      0.76      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's focal_loss: 0.00331787\tvalid_1's focal_loss: 0.0154199\n",
      "4 val f1 0.920329841415865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.93      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.94      1632\n",
      "   macro avg       0.94      0.91      0.92      1632\n",
      "weighted avg       0.94      0.94      0.94      1632\n",
      "\n",
      "oof f1 0.9159669220598143\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91597_2020-02-26-15-31-23\n",
      "围网 oof f1 0.9515928837401738\n",
      "------------------------------------------------ w2c_label-d.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's focal_loss: 0.00184153\tvalid_1's focal_loss: 0.0139578\n",
      "0 val f1 0.920088844495869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.93      0.80      0.86       267\n",
      "\n",
      "    accuracy                           0.94      1635\n",
      "   macro avg       0.94      0.91      0.92      1635\n",
      "weighted avg       0.94      0.94      0.94      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's focal_loss: 0.00136734\tvalid_1's focal_loss: 0.0139378\n",
      "1 val f1 0.9272345707099262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.94      0.82      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.92      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00273222\tvalid_1's focal_loss: 0.0149062\n",
      "2 val f1 0.9123390788606459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.77      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's focal_loss: 0.00259399\tvalid_1's focal_loss: 0.0164203\n",
      "3 val f1 0.9047417668926879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.91      0.76      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.92      0.89      0.90      1632\n",
      "weighted avg       0.93      0.93      0.92      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's focal_loss: 0.00325349\tvalid_1's focal_loss: 0.0152538\n",
      "4 val f1 0.9187795568691491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       658\n",
      "           1       0.93      0.99      0.96       708\n",
      "           2       0.93      0.79      0.86       266\n",
      "\n",
      "    accuracy                           0.94      1632\n",
      "   macro avg       0.94      0.91      0.92      1632\n",
      "weighted avg       0.94      0.94      0.94      1632\n",
      "\n",
      "oof f1 0.9166896679567076\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91669_2020-02-26-15-36-40\n",
      "围网 oof f1 0.9520396912899669\n",
      "------------------------------------------------ w2c_label-date.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's focal_loss: 0.002515\tvalid_1's focal_loss: 0.0144382\n",
      "0 val f1 0.9138070732742057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.93      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's focal_loss: 0.00184578\tvalid_1's focal_loss: 0.0141305\n",
      "1 val f1 0.9244082012697229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.95      0.81      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's focal_loss: 0.00312515\tvalid_1's focal_loss: 0.0153044\n",
      "2 val f1 0.9136969077505065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00264989\tvalid_1's focal_loss: 0.0162506\n",
      "3 val f1 0.9106321530932419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.94      0.76      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's focal_loss: 0.0029995\tvalid_1's focal_loss: 0.0152987\n",
      "4 val f1 0.9159777061449828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.91      0.80      0.85       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oof f1 0.9157396743278371\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91574_2020-02-26-15-42-07\n",
      "围网 oof f1 0.9512799339388934\n",
      "------------------------------------------------ w2c_label-v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's focal_loss: 0.00202539\tvalid_1's focal_loss: 0.0143097\n",
      "0 val f1 0.912128057140467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's focal_loss: 0.00226147\tvalid_1's focal_loss: 0.0141438\n",
      "1 val f1 0.927646658717478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.96      0.81      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.95      0.91      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's focal_loss: 0.00370314\tvalid_1's focal_loss: 0.0149843\n",
      "2 val f1 0.9169676631868554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.94      0.97      0.95       708\n",
      "           2       0.92      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.94      1633\n",
      "   macro avg       0.93      0.91      0.92      1633\n",
      "weighted avg       0.93      0.94      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's focal_loss: 0.00279866\tvalid_1's focal_loss: 0.0158849\n",
      "3 val f1 0.9110340669981193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.95      0.76      0.85       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's focal_loss: 0.00323729\tvalid_1's focal_loss: 0.0151432\n",
      "4 val f1 0.917262195018327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.79      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9170196211098304\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91702_2020-02-26-15-47-26\n",
      "围网 oof f1 0.951410874053682\n",
      "------------------------------------------------ w2c_max_v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.00213733\tvalid_1's focal_loss: 0.0145531\n",
      "0 val f1 0.9121173826368681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's focal_loss: 0.00166682\tvalid_1's focal_loss: 0.0138708\n",
      "1 val f1 0.9303808630393998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.95      0.83      0.89       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.92      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's focal_loss: 0.00333036\tvalid_1's focal_loss: 0.0153767\n",
      "2 val f1 0.9089939775768116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.76      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.89      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's focal_loss: 0.00233411\tvalid_1's focal_loss: 0.0157754\n",
      "3 val f1 0.9130357998883568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.93      0.77      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's focal_loss: 0.003578\tvalid_1's focal_loss: 0.0150144\n",
      "4 val f1 0.9187004325000089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.94      1632\n",
      "   macro avg       0.94      0.91      0.92      1632\n",
      "weighted avg       0.94      0.94      0.93      1632\n",
      "\n",
      "oof f1 0.9167095927715377\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91671_2020-02-26-15-53-10\n",
      "围网 oof f1 0.9514376117760353\n",
      "------------------------------------------------ w2c_min_v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's focal_loss: 0.00141748\tvalid_1's focal_loss: 0.0145122\n",
      "0 val f1 0.9140288225859216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.93      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's focal_loss: 0.00148759\tvalid_1's focal_loss: 0.0141531\n",
      "1 val f1 0.9287614592694119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.96      0.82      0.89       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.92      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's focal_loss: 0.0029423\tvalid_1's focal_loss: 0.0150104\n",
      "2 val f1 0.9133855956020295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00266449\tvalid_1's focal_loss: 0.0160473\n",
      "3 val f1 0.9103524326355946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.94      0.76      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's focal_loss: 0.00301553\tvalid_1's focal_loss: 0.0152104\n",
      "4 val f1 0.9231110582945948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       658\n",
      "           1       0.93      0.99      0.96       708\n",
      "           2       0.94      0.81      0.87       266\n",
      "\n",
      "    accuracy                           0.94      1632\n",
      "   macro avg       0.94      0.91      0.92      1632\n",
      "weighted avg       0.94      0.94      0.94      1632\n",
      "\n",
      "oof f1 0.9179887131176138\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91799_2020-02-26-15-58-47\n",
      "围网 oof f1 0.95274831243973\n",
      "------------------------------------------------ w2c_std_label-v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's focal_loss: 0.00190791\tvalid_1's focal_loss: 0.014506\n",
      "0 val f1 0.9083930988712989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.96      0.94       709\n",
      "           2       0.92      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.92      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's focal_loss: 0.00182652\tvalid_1's focal_loss: 0.0135985\n",
      "1 val f1 0.9228106472444152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.81      0.87       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's focal_loss: 0.00221013\tvalid_1's focal_loss: 0.0152048\n",
      "2 val f1 0.9174249060564694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.94      1633\n",
      "   macro avg       0.94      0.90      0.92      1633\n",
      "weighted avg       0.94      0.94      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's focal_loss: 0.0025293\tvalid_1's focal_loss: 0.0162399\n",
      "3 val f1 0.9085829236771378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.76      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's focal_loss: 0.00414462\tvalid_1's focal_loss: 0.0153341\n",
      "4 val f1 0.9163776123283375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9147496655547612\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91475_2020-02-26-16-03-29\n",
      "围网 oof f1 0.9505441520870642\n",
      "------------------------------------------------ w2c_std_v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's focal_loss: 0.0016808\tvalid_1's focal_loss: 0.0143661\n",
      "0 val f1 0.9141729994981039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's focal_loss: 0.00191003\tvalid_1's focal_loss: 0.0140805\n",
      "1 val f1 0.9219424543886466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.81      0.87       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's focal_loss: 0.00345991\tvalid_1's focal_loss: 0.01459\n",
      "2 val f1 0.9158977237455206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.94      0.97      0.95       708\n",
      "           2       0.92      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.94      1633\n",
      "   macro avg       0.93      0.90      0.92      1633\n",
      "weighted avg       0.94      0.94      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's focal_loss: 0.00241417\tvalid_1's focal_loss: 0.0164132\n",
      "3 val f1 0.9062569451044089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.91      0.76      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.92      0.89      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's focal_loss: 0.00371825\tvalid_1's focal_loss: 0.0154462\n",
      "4 val f1 0.913869861056043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oof f1 0.9144662868758191\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91447_2020-02-26-16-08-01\n",
      "围网 oof f1 0.9520661157024795\n",
      "------------------------------------------------ w2c_std_x-y-10.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.0021365\tvalid_1's focal_loss: 0.0143082\n",
      "0 val f1 0.9150479690539406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       659\n",
      "           1       0.92      0.97      0.95       709\n",
      "           2       0.93      0.79      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.92      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's focal_loss: 0.00163766\tvalid_1's focal_loss: 0.0140774\n",
      "1 val f1 0.9189803615604083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.95      0.79      0.86       267\n",
      "\n",
      "    accuracy                           0.93      1634\n",
      "   macro avg       0.94      0.90      0.92      1634\n",
      "weighted avg       0.94      0.93      0.93      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.00211195\tvalid_1's focal_loss: 0.0147601\n",
      "2 val f1 0.915485407976892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.92      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's focal_loss: 0.00256188\tvalid_1's focal_loss: 0.0157131\n",
      "3 val f1 0.9127212951077336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.77      0.85       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's focal_loss: 0.00307337\tvalid_1's focal_loss: 0.0150676\n",
      "4 val f1 0.9179029951667915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9160384687280931\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91604_2020-02-26-16-12-41\n",
      "围网 oof f1 0.9503233796614834\n",
      "------------------------------------------------ w2c_std_x-y-1000.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's focal_loss: 0.00223559\tvalid_1's focal_loss: 0.0144759\n",
      "0 val f1 0.9116425160099859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.93      0.96      0.95       709\n",
      "           2       0.91      0.79      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's focal_loss: 0.0015947\tvalid_1's focal_loss: 0.0138207\n",
      "1 val f1 0.9289763020764629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.95      0.82      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.92      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.00214807\tvalid_1's focal_loss: 0.0152522\n",
      "2 val f1 0.9185134812155322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       658\n",
      "           1       0.94      0.96      0.95       708\n",
      "           2       0.92      0.80      0.86       267\n",
      "\n",
      "    accuracy                           0.94      1633\n",
      "   macro avg       0.93      0.91      0.92      1633\n",
      "weighted avg       0.94      0.94      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00267725\tvalid_1's focal_loss: 0.0160577\n",
      "3 val f1 0.9100406230442747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.76      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's focal_loss: 0.00347094\tvalid_1's focal_loss: 0.0151739\n",
      "4 val f1 0.9168854595811683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9172519075537373\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91725_2020-02-26-16-17-21\n",
      "围网 oof f1 0.9526439320723457\n",
      "------------------------------------------------ w2c_v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's focal_loss: 0.00217686\tvalid_1's focal_loss: 0.0143332\n",
      "0 val f1 0.9132910910799744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.94      0.77      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's focal_loss: 0.00188046\tvalid_1's focal_loss: 0.0142037\n",
      "1 val f1 0.9222907984094965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.81      0.87       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00279952\tvalid_1's focal_loss: 0.0154321\n",
      "2 val f1 0.9122645498917262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.77      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's focal_loss: 0.00265522\tvalid_1's focal_loss: 0.0157185\n",
      "3 val f1 0.9119597869974331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.94      0.77      0.84       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.90      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's focal_loss: 0.00324889\tvalid_1's focal_loss: 0.0149177\n",
      "4 val f1 0.9161602951777272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.915231939968392\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91523_2020-02-26-16-21-50\n",
      "围网 oof f1 0.9519878937955703\n",
      "------------------------------------------------ w2c_x-100.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's focal_loss: 0.00166545\tvalid_1's focal_loss: 0.0141982\n",
      "0 val f1 0.9184102825656425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.94      0.79      0.86       267\n",
      "\n",
      "    accuracy                           0.94      1635\n",
      "   macro avg       0.94      0.91      0.92      1635\n",
      "weighted avg       0.94      0.94      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's focal_loss: 0.0014044\tvalid_1's focal_loss: 0.0139738\n",
      "1 val f1 0.9237170045874161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.93      0.82      0.87       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's focal_loss: 0.00245988\tvalid_1's focal_loss: 0.015293\n",
      "2 val f1 0.913193528735845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.78      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.00276851\tvalid_1's focal_loss: 0.0157388\n",
      "3 val f1 0.9074369771925204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.76      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.91      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's focal_loss: 0.0037805\tvalid_1's focal_loss: 0.0154374\n",
      "4 val f1 0.9168205837173113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9159603374992611\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91596_2020-02-26-16-26-15\n",
      "围网 oof f1 0.9517640573318632\n",
      "------------------------------------------------ w2c_x-y-10.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's focal_loss: 0.00236285\tvalid_1's focal_loss: 0.0142628\n",
      "0 val f1 0.9172740177833051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       659\n",
      "           1       0.94      0.97      0.95       709\n",
      "           2       0.93      0.79      0.86       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.91      0.92      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's focal_loss: 0.00232345\tvalid_1's focal_loss: 0.0141631\n",
      "1 val f1 0.9218630900919177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.80      0.86       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.91      0.92      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's focal_loss: 0.0028377\tvalid_1's focal_loss: 0.0147953\n",
      "2 val f1 0.9128188580421782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.92      0.77      0.84       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's focal_loss: 0.00269837\tvalid_1's focal_loss: 0.0165494\n",
      "3 val f1 0.9047582897318107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.92      0.97      0.95       708\n",
      "           2       0.93      0.75      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.90      1632\n",
      "weighted avg       0.93      0.93      0.92      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's focal_loss: 0.00250353\tvalid_1's focal_loss: 0.0146275\n",
      "4 val f1 0.9178131935532327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.92      0.80      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oof f1 0.9149533439343753\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91495_2020-02-26-16-31-23\n",
      "围网 oof f1 0.9514884233737596\n",
      "------------------------------------------------ w2c_x-y-1000.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-v.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's focal_loss: 0.00233805\tvalid_1's focal_loss: 0.0152342\n",
      "0 val f1 0.9044320092995338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       659\n",
      "           1       0.92      0.97      0.94       709\n",
      "           2       0.92      0.76      0.83       267\n",
      "\n",
      "    accuracy                           0.92      1635\n",
      "   macro avg       0.92      0.89      0.90      1635\n",
      "weighted avg       0.92      0.92      0.92      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's focal_loss: 0.00156362\tvalid_1's focal_loss: 0.0146911\n",
      "1 val f1 0.9165226326796155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       659\n",
      "           1       0.92      0.98      0.95       708\n",
      "           2       0.94      0.79      0.86       267\n",
      "\n",
      "    accuracy                           0.93      1634\n",
      "   macro avg       0.93      0.90      0.92      1634\n",
      "weighted avg       0.93      0.93      0.93      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's focal_loss: 0.00351847\tvalid_1's focal_loss: 0.0159351\n",
      "2 val f1 0.9081743085237296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.91      0.76      0.83       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.91      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's focal_loss: 0.00373824\tvalid_1's focal_loss: 0.0170803\n",
      "3 val f1 0.9049425717330593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       658\n",
      "           1       0.92      0.97      0.95       708\n",
      "           2       0.92      0.76      0.83       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.89      0.90      1632\n",
      "weighted avg       0.93      0.93      0.92      1632\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's focal_loss: 0.00341604\tvalid_1's focal_loss: 0.0157777\n",
      "4 val f1 0.917837507866781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       658\n",
      "           1       0.93      0.98      0.96       708\n",
      "           2       0.92      0.81      0.86       266\n",
      "\n",
      "    accuracy                           0.93      1632\n",
      "   macro avg       0.93      0.91      0.92      1632\n",
      "weighted avg       0.93      0.93      0.93      1632\n",
      "\n",
      "oof f1 0.9104262094778702\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: pred, dtype: float64\n",
      "result_0.91043_2020-02-26-16-36-05\n",
      "围网 oof f1 0.9490778970547756\n",
      "------------------------------------------------ w2c_x-y-v.csv\n",
      "w2c_d.csv\n",
      "w2c_date-v.csv\n",
      "w2c_date.csv\n",
      "w2c_label-d.csv\n",
      "w2c_label-date.csv\n",
      "w2c_label-v.csv\n",
      "w2c_max_v.csv\n",
      "w2c_min_v.csv\n",
      "w2c_std_label-v.csv\n",
      "w2c_std_v.csv\n",
      "w2c_std_x-y-10.csv\n",
      "w2c_std_x-y-1000.csv\n",
      "w2c_v.csv\n",
      "w2c_x-100.csv\n",
      "w2c_x-y-10.csv\n",
      "w2c_x-y-1000.csv\n",
      "w2c_y-100.csv\n",
      "特征数量 1172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's focal_loss: 0.00235808\tvalid_1's focal_loss: 0.0144205\n",
      "0 val f1 0.9138806523414184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       659\n",
      "           1       0.93      0.97      0.95       709\n",
      "           2       0.92      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1635\n",
      "   macro avg       0.93      0.90      0.91      1635\n",
      "weighted avg       0.93      0.93      0.93      1635\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's focal_loss: 0.00253104\tvalid_1's focal_loss: 0.0145733\n",
      "1 val f1 0.9277081215309767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       659\n",
      "           1       0.93      0.98      0.95       708\n",
      "           2       0.96      0.82      0.88       267\n",
      "\n",
      "    accuracy                           0.94      1634\n",
      "   macro avg       0.94      0.92      0.93      1634\n",
      "weighted avg       0.94      0.94      0.94      1634\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's focal_loss: 0.00232603\tvalid_1's focal_loss: 0.0155264\n",
      "2 val f1 0.915039069943618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       658\n",
      "           1       0.93      0.97      0.95       708\n",
      "           2       0.93      0.78      0.85       267\n",
      "\n",
      "    accuracy                           0.93      1633\n",
      "   macro avg       0.93      0.90      0.92      1633\n",
      "weighted avg       0.93      0.93      0.93      1633\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a16c01376c1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mindex_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_list_val\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mget_fold_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_list_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"submit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\jupyter\\智慧海洋\\tianchi_ship_2019-master\\working\\dock\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(index_list, index_list_val, train_label, test_label, features, target)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_focalloss\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             model = lgb.train(params, train_set, fobj=focal_loss, feval=eval_error,\n\u001b[1;32m--> 175\u001b[1;33m                         valid_sets=[train_set, val_set], verbose_eval=300)\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0muse_focalloss\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             model = lgb.train(params, train_set, fobj=focal_loss, feval=lgb_f1_score,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1931\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1932\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1933\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__boost\u001b[1;34m(self, grad, hess)\u001b[0m\n\u001b[0;32m   1966\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1967\u001b[0m             \u001b[0mhess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1968\u001b[1;33m             ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1969\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from get_all_feature  import output_finally_test_feature\n",
    "from datapre import main_datapre\n",
    "from Feature_Engineering_base import main_base\n",
    "from Feature_Engineering_w2v import main_w2v\n",
    "from Feature_Engineering_bin import main_bin\n",
    "from get_all_feature import get_feature,get_fold_index\n",
    "from model import submit_file,train,train2\n",
    "score = []\n",
    "l = os.listdir(root_path)\n",
    "num = len(l)\n",
    "for i in range(num):\n",
    "    l = os.listdir(root_path)\n",
    "    print(\"------------------------------------------------\",l[i])\n",
    "    l.remove(l[i])\n",
    "    name = l\n",
    "    output_finally_feature2(name)\n",
    "    feature_path = \"./temp/finally_feature/\"\n",
    "\n",
    "    if config.mode == \"train\":\n",
    "        train_label=pd.read_csv(feature_path+\"train_label_88.csv\")\n",
    "\n",
    "        test_label=pd.read_csv(feature_path+\"test_label_88.csv\")\n",
    "        features,target= get_feature()\n",
    "        index_list,index_list_val= get_fold_index(train_label,test_label)\n",
    "\n",
    "        c= train(index_list,index_list_val,train_label,test_label,features,target)\n",
    "        score.append(c)\n",
    "    elif config.mode == \"submit\":\n",
    "        test_label=pd.read_csv(feature_path+\"test_label_88.csv\")\n",
    "        submit_file(test_label,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:40:36.953060Z",
     "start_time": "2020-02-26T08:40:36.928077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d 0.9159898385414591\n",
    "date  0.9174973120578344\n",
    "label-date 0.9168471743792889\n",
    "max_v 0.9136844443404838\n",
    "std_label-v 0.9169007554889731\n",
    "std_x-y-10 0.9153870172357808\n",
    "v 0.9161154116653409\n",
    "0.9179693215133519\n",
    "x-y-10 x-y-v 0.9119226006426219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "0.9104626059322801\n",
    "\n",
    "# 改了五折的geoid\n",
    "0.91549742299034\n",
    "\n",
    "# 加了新的\n",
    "0.9087290412022083\n",
    "\n",
    "# \n",
    "0.9163581135014972\n",
    "0.9158117974605102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T06:21:22.506063Z",
     "start_time": "2020-02-26T06:21:22.493061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.433627\n",
       "0    0.403135\n",
       "2    0.163238\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[\"type\"].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        old_train_label = pd.read_csv(\"train_label_88.csv\")\n",
    "        old_train_label =old_train_label[old_train_label[\"type\"] == 2]\n",
    "        col = [\"ship\",'v',\"type\",\n",
    "        'v_max','v_min','v_mean','v_std','v_skew','v_sum',\n",
    "               'd_max',\n",
    "     'd_min',\n",
    "     'd_mean',\n",
    "     'd_std',\n",
    "     'd_skew',\n",
    "     'd_sum',\n",
    "        ]\n",
    "        train_label = pd.concat([train_label,old_train_label[col]])\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "        for i in range(1,6):\n",
    "            index_list[str(i)] = np.append(index_list[str(i)],np.arange(8162,8162+old_train_label.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
